{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lem =WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c9aba8a60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"].replace(0,value=\"negative\",inplace=True)\n",
    "df[\"Sentiment\"].replace(1,value=\"negative\",inplace=True)\n",
    "\n",
    "df[\"Sentiment\"].replace(3,value=\"positive\",inplace=True)\n",
    "df[\"Sentiment\"].replace(4,value=\"positive\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Sentiment\"]!=2].sample(36000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c9ac95b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.DataFrame()\n",
    "data[\"sentences\"] = df[\"Phrase\"]\n",
    "data[\"label\"] = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "promotes       1\n",
       "pro-Serb       1\n",
       "teendom        1\n",
       "Grabowsky      1\n",
       "spinoff        1\n",
       "              ..\n",
       "sisterhood     1\n",
       "peaked         1\n",
       "Teacher        1\n",
       "deliriously    1\n",
       "wallowing      1\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words = pd.Series(\" \".join(data[\"sentences\"]).split()).value_counts()[-1000:]\n",
    "rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentences\"] = data[\"sentences\"].apply(lambda x : \" \".join(x for x in x.split() if x not in rare_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49537                          the best silly horror movies\n",
       "65509                                               restate\n",
       "58716                                  smart and newfangled\n",
       "44598     is hugely overwritten , with tons and tons of ...\n",
       "43933                                             about ten\n",
       "                                ...                        \n",
       "73254     remarkable procession of sweeping pictures tha...\n",
       "107693     Somewhere inside the mess that is World Traveler\n",
       "109360                                   be liked sometimes\n",
       "139649    An entertaining mix of period drama and flat-o...\n",
       "118587    a technological exercise that lacks juice and ...\n",
       "Name: sentences, Length: 36000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lem =WordNetLemmatizer()\n",
    "\n",
    "def cleaning(data):\n",
    "    # tokenize\n",
    "    text_tokens = word_tokenize(data.lower())\n",
    "    # Remove puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    # removing stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    #lemma\n",
    "    text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
    "    # joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentences2\"] = data[\"sentences\"].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49537                               best silly horror movie\n",
       "65509                                               restate\n",
       "58716                                      smart newfangled\n",
       "44598       hugely overwritten ton ton dialogue given child\n",
       "43933                                                   ten\n",
       "                                ...                        \n",
       "73254     remarkable procession sweeping picture reinvig...\n",
       "107693                 somewhere inside mess world traveler\n",
       "109360                                      liked sometimes\n",
       "139649    entertaining mix period drama farce please his...\n",
       "118587            technological exercise lack juice delight\n",
       "Name: sentences2, Length: 36000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentences2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"sentences2\"],data[\"label\"], test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map({\"negative\":0 ,\"positive\":1})\n",
    "\n",
    "y_test=y_test.map({\"negative\":0 ,\"positive\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151379    1\n",
       "123551    0\n",
       "11380     1\n",
       "149904    0\n",
       "28247     0\n",
       "         ..\n",
       "55906     1\n",
       "22283     0\n",
       "115439    0\n",
       "126348    1\n",
       "145976    0\n",
       "Name: label, Length: 27000, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = vectorizer.transform(X_train)\n",
    "X_test_count = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'aaliyah',\n",
       " 'abagnale',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbass',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abiding',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'aborted',\n",
       " 'abound',\n",
       " 'abrasive',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accentuating',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accommodate',\n",
       " 'accompanies',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achival',\n",
       " 'acidic',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acolyte',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acrid',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'activate',\n",
       " 'activism',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actorish',\n",
       " 'actorliness',\n",
       " 'actorly',\n",
       " 'actory',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuary',\n",
       " 'acumen',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'addressing',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherent',\n",
       " 'adhering',\n",
       " 'adjective',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'ado',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adored',\n",
       " 'adoring',\n",
       " 'adorns',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalized',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventues',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advises',\n",
       " 'advocacy',\n",
       " 'aerial',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'affords',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'aficionado',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterwards',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggrandizing',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agitprop',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agreeably',\n",
       " 'agreement',\n",
       " 'aground',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahola',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aiello',\n",
       " 'ailment',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aimlessness',\n",
       " 'air',\n",
       " 'airhead',\n",
       " 'airless',\n",
       " 'aisle',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'aladdin',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarming',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcatraz',\n",
       " 'alchemical',\n",
       " 'alert',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluring',\n",
       " 'allusion',\n",
       " 'ally',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloof',\n",
       " 'already',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'alteration',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'amalgam',\n",
       " 'amaro',\n",
       " 'amassed',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amaze',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambience',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'amble',\n",
       " 'ambrose',\n",
       " 'amc',\n",
       " 'ame',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'amiable',\n",
       " 'amiably',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'among',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusement',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'ana',\n",
       " 'anachronistic',\n",
       " 'anakin',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'anarchist',\n",
       " 'anatomical',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'anchoring',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andie',\n",
       " 'andrei',\n",
       " 'android',\n",
       " 'anecdote',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angelina',\n",
       " 'angelique',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angling',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anguish',\n",
       " 'anguished',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animaton',\n",
       " 'animator',\n",
       " 'animatronic',\n",
       " 'anime',\n",
       " 'aniston',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annex',\n",
       " 'anniversary',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'anomaly',\n",
       " 'anomie',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'anteing',\n",
       " 'anthony',\n",
       " 'anthropomorphic',\n",
       " 'antic',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'antique',\n",
       " 'antiseptic',\n",
       " 'antitrust',\n",
       " 'anton',\n",
       " 'antonia',\n",
       " 'antonio',\n",
       " 'antsy',\n",
       " 'antwone',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apex',\n",
       " 'aplenty',\n",
       " 'aplomb',\n",
       " 'apocalypse',\n",
       " 'apollo',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appealingly',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'appetizer',\n",
       " 'appetizing',\n",
       " 'apple',\n",
       " 'applegate',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'april',\n",
       " 'apted',\n",
       " 'aptitude',\n",
       " 'aragorn',\n",
       " 'aranda',\n",
       " 'ararat',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'archetypal',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'archly',\n",
       " 'arctic',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'arduous',\n",
       " 'area',\n",
       " 'argentine',\n",
       " 'argentinian',\n",
       " 'argento',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arising',\n",
       " 'aristocracy',\n",
       " 'aristocrat',\n",
       " 'arithmetic',\n",
       " 'arkansas',\n",
       " 'arliss',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'armenian',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arresting',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'articulate',\n",
       " 'articulates',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artiste',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artless',\n",
       " 'artnering',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'arwen',\n",
       " 'ascends',\n",
       " 'ascension',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiaphiles',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'aspiration',\n",
       " 'aspire',\n",
       " 'aspires',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assaultive',\n",
       " 'assayas',\n",
       " 'assembled',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assures',\n",
       " 'astonish',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astounds',\n",
       " 'astray',\n",
       " 'astringent',\n",
       " 'astronaut',\n",
       " 'astronomically',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'ate',\n",
       " 'athlete',\n",
       " 'athleticism',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherics',\n",
       " 'atop',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacker',\n",
       " 'attal',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attendant',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attributable',\n",
       " 'attuned',\n",
       " 'atypically',\n",
       " 'audacious',\n",
       " 'audacity',\n",
       " 'audiard',\n",
       " 'audience',\n",
       " 'auditorium',\n",
       " 'august',\n",
       " 'aurelie',\n",
       " 'auspicious',\n",
       " 'aussie',\n",
       " 'austen',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austrian',\n",
       " 'auteil',\n",
       " 'auteuil',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticate',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autobiographical',\n",
       " 'autocritique',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'autopsy',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avant',\n",
       " 'avarice',\n",
       " 'avary',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'aversion',\n",
       " 'avert',\n",
       " 'averting',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'avuncular',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'awakens',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awash',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfulness',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'awry',\n",
       " 'ayatollah',\n",
       " 'ayurveda',\n",
       " 'baaaaaaaaad',\n",
       " 'babak',\n",
       " 'babbitt',\n",
       " 'babe',\n",
       " 'baboon',\n",
       " 'baby',\n",
       " 'babysitter',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backdrop',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backhanded',\n",
       " 'backlash',\n",
       " 'backmasking',\n",
       " 'backseat',\n",
       " 'backstage',\n",
       " 'backward',\n",
       " 'backwater',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badder',\n",
       " 'badly',\n",
       " 'badness',\n",
       " 'baffle',\n",
       " 'baffled',\n",
       " 'baffling',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'bailiwick',\n",
       " 'bailly',\n",
       " 'baio',\n",
       " 'baird',\n",
       " 'baked',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'bald',\n",
       " 'balding',\n",
       " 'bale',\n",
       " 'balk',\n",
       " 'ball',\n",
       " 'ballast',\n",
       " 'ballerina',\n",
       " 'ballet',\n",
       " 'ballistic',\n",
       " 'ballot',\n",
       " 'ballplayer',\n",
       " 'ballroom',\n",
       " 'ballsy',\n",
       " 'balm',\n",
       " 'baloney',\n",
       " 'balto',\n",
       " 'balzac',\n",
       " 'bambi',\n",
       " 'banal',\n",
       " 'banality',\n",
       " 'band',\n",
       " 'banderas',\n",
       " 'bang',\n",
       " 'banged',\n",
       " 'banger',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banter',\n",
       " 'banzai',\n",
       " 'bar',\n",
       " 'baran',\n",
       " 'barbara',\n",
       " 'barbarian',\n",
       " 'barbarism',\n",
       " 'barbed',\n",
       " 'barber',\n",
       " 'barbershop',\n",
       " 'bard',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'barf',\n",
       " 'bark',\n",
       " 'barker',\n",
       " 'barlow',\n",
       " 'barney',\n",
       " 'baroque',\n",
       " 'barrage',\n",
       " 'barrel',\n",
       " 'barrie',\n",
       " 'barris',\n",
       " 'barrow',\n",
       " 'barry',\n",
       " 'barrymore',\n",
       " 'bart',\n",
       " 'bartleby',\n",
       " 'bartlett',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basest',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'bask',\n",
       " 'basketball',\n",
       " 'bastard',\n",
       " 'batch',\n",
       " 'bates',\n",
       " 'bath',\n",
       " 'bathing',\n",
       " 'bathos',\n",
       " 'bathroom',\n",
       " 'bathtub',\n",
       " 'batman',\n",
       " 'battered',\n",
       " 'battery',\n",
       " 'batting',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'bawdy',\n",
       " 'bazadona',\n",
       " 'beach',\n",
       " 'beachcombing',\n",
       " 'beacon',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bearable',\n",
       " 'beard',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beause',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bebe',\n",
       " 'becalmed',\n",
       " 'became',\n",
       " 'becker',\n",
       " 'beckons',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedeviled',\n",
       " 'bedevilling',\n",
       " 'bedfellow',\n",
       " 'bedknobs',\n",
       " 'bedroom',\n",
       " 'bedside',\n",
       " 'bedtime',\n",
       " 'beer',\n",
       " 'befallen',\n",
       " 'befuddled',\n",
       " 'befuddling',\n",
       " 'beg',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginner',\n",
       " 'beginning',\n",
       " 'begley',\n",
       " 'begrudge',\n",
       " 'begs',\n",
       " 'beguiling',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaving',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'beheading',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beijing',\n",
       " 'being',\n",
       " 'bela',\n",
       " 'belgian',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believability',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'believing',\n",
       " 'belinsky',\n",
       " 'belly',\n",
       " 'bellyaching',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'bemused',\n",
       " 'ben',\n",
       " 'benchmark',\n",
       " 'bender',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benefited',\n",
       " 'benevolent',\n",
       " 'benigni',\n",
       " 'benjamin',\n",
       " 'benshan',\n",
       " 'bent',\n",
       " 'berg',\n",
       " 'bergmanesque',\n",
       " 'berkeley',\n",
       " 'berkley',\n",
       " 'berlin',\n",
       " 'bermuda',\n",
       " 'bernard',\n",
       " 'berry',\n",
       " 'bertrand',\n",
       " 'besco',\n",
       " 'beseechingly',\n",
       " 'besides',\n",
       " 'besotted',\n",
       " 'bespeaks',\n",
       " 'besson',\n",
       " 'best',\n",
       " 'bestial',\n",
       " 'bestowing',\n",
       " 'bet',\n",
       " 'betrayal',\n",
       " 'betrayed',\n",
       " 'bettany',\n",
       " 'bette',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'betty',\n",
       " 'bewildered',\n",
       " 'bewildering',\n",
       " 'bewilderingly',\n",
       " 'bewitched',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biblical',\n",
       " 'bicentennial',\n",
       " 'bickering',\n",
       " 'bickle',\n",
       " 'bid',\n",
       " 'bidder',\n",
       " 'bielinsky',\n",
       " 'big',\n",
       " 'bigelow',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bile',\n",
       " 'bilingual',\n",
       " 'bilked',\n",
       " 'bill',\n",
       " 'bille',\n",
       " 'billing',\n",
       " 'billy',\n",
       " 'binary',\n",
       " 'bind',\n",
       " 'binks',\n",
       " 'binoche',\n",
       " 'biographical',\n",
       " 'biography',\n",
       " 'biologically',\n",
       " 'biopic',\n",
       " 'birmingham',\n",
       " 'birot',\n",
       " 'birthday',\n",
       " 'bisset',\n",
       " 'bit',\n",
       " 'bitchy',\n",
       " 'bite',\n",
       " 'biting',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'bitterly',\n",
       " 'bittersweet',\n",
       " 'biz',\n",
       " 'bizarre',\n",
       " 'bjorkness',\n",
       " 'blab',\n",
       " 'black',\n",
       " 'blacked',\n",
       " 'blacken',\n",
       " 'blade',\n",
       " 'bladerunner',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blame',\n",
       " 'blanchett',\n",
       " 'bland',\n",
       " 'blandly',\n",
       " 'blandness',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blarney',\n",
       " 'blasphemous',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'blaxploitation',\n",
       " 'blazing',\n",
       " 'blazingly',\n",
       " 'bleak',\n",
       " 'bleakness',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(X_train_count.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>abagnale</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbass</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abhorrent</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zishe</th>\n",
       "      <th>ziyi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoolander</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27000 rows Ã— 11252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaa  aaliyah  abagnale  abandon  abandoned  abbass  abbott  abc  abdul  \\\n",
       "0        0        0         0        0          0       0       0    0      0   \n",
       "1        0        0         0        0          0       0       0    0      0   \n",
       "2        0        0         0        0          0       0       0    0      0   \n",
       "3        0        0         0        0          0       0       0    0      0   \n",
       "4        0        0         0        0          0       0       0    0      0   \n",
       "...    ...      ...       ...      ...        ...     ...     ...  ...    ...   \n",
       "26995    0        0         0        0          0       0       0    0      0   \n",
       "26996    0        0         0        0          0       0       0    0      0   \n",
       "26997    0        0         0        0          0       0       0    0      0   \n",
       "26998    0        0         0        0          0       0       0    0      0   \n",
       "26999    0        0         0        0          0       0       0    0      0   \n",
       "\n",
       "       abhorrent  ...  zipper  zippy  zishe  ziyi  zoe  zombie  zone  zoning  \\\n",
       "0              0  ...       0      0      0     0    0       0     0       0   \n",
       "1              0  ...       0      0      0     0    0       0     0       0   \n",
       "2              0  ...       0      0      0     0    0       0     0       0   \n",
       "3              0  ...       0      0      0     0    0       0     0       0   \n",
       "4              0  ...       0      0      0     0    0       0     0       0   \n",
       "...          ...  ...     ...    ...    ...   ...  ...     ...   ...     ...   \n",
       "26995          0  ...       0      0      0     0    0       0     0       0   \n",
       "26996          0  ...       0      0      0     0    0       0     0       0   \n",
       "26997          0  ...       0      0      0     0    0       0     0       0   \n",
       "26998          0  ...       0      0      0     0    0       0     0       0   \n",
       "26999          0  ...       0      0      0     0    0       0     0       0   \n",
       "\n",
       "       zoolander  zwick  \n",
       "0              0      0  \n",
       "1              0      0  \n",
       "2              0      0  \n",
       "3              0      0  \n",
       "4              0      0  \n",
       "...          ...    ...  \n",
       "26995          0      0  \n",
       "26996          0      0  \n",
       "26997          0      0  \n",
       "26998          0      0  \n",
       "26999          0      0  \n",
       "\n",
       "[27000 rows x 11252 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf = tf_idf.transform(X_train)\n",
    "X_test_tf_idf = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(X_train_tf_idf.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>abagnale</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbass</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abhorrent</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zishe</th>\n",
       "      <th>ziyi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoolander</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27000 rows Ã— 11252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaa  aaliyah  abagnale  abandon  abandoned  abbass  abbott  abc  abdul  \\\n",
       "0      0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "1      0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "2      0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "3      0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "4      0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "...    ...      ...       ...      ...        ...     ...     ...  ...    ...   \n",
       "26995  0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "26996  0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "26997  0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "26998  0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "26999  0.0      0.0       0.0      0.0        0.0     0.0     0.0  0.0    0.0   \n",
       "\n",
       "       abhorrent  ...  zipper  zippy  zishe  ziyi  zoe  zombie  zone  zoning  \\\n",
       "0            0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "1            0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "2            0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "3            0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "4            0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "...          ...  ...     ...    ...    ...   ...  ...     ...   ...     ...   \n",
       "26995        0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "26996        0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "26997        0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "26998        0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "26999        0.0  ...     0.0    0.0    0.0   0.0  0.0     0.0   0.0     0.0   \n",
       "\n",
       "       zoolander  zwick  \n",
       "0            0.0    0.0  \n",
       "1            0.0    0.0  \n",
       "2            0.0    0.0  \n",
       "3            0.0    0.0  \n",
       "4            0.0    0.0  \n",
       "...          ...    ...  \n",
       "26995        0.0    0.0  \n",
       "26996        0.0    0.0  \n",
       "26997        0.0    0.0  \n",
       "26998        0.0    0.0  \n",
       "26999        0.0    0.0  \n",
       "\n",
       "[27000 rows x 11252 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tf_idf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=nb.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7576\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = nb.predict(X_test_count) - y_test\n",
    "aa[aa==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5008\n",
       "0    3992\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3113  879]\n",
      " [ 545 4463]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81      3992\n",
      "           1       0.84      0.89      0.86      5008\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.84      0.84      9000\n",
      "weighted avg       0.84      0.84      0.84      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial DB wit TFidf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tf_idf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = nb.predict(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3105  887]\n",
      " [ 504 4504]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      3992\n",
      "           1       0.84      0.90      0.87      5008\n",
      "\n",
      "    accuracy                           0.85      9000\n",
      "   macro avg       0.85      0.84      0.84      9000\n",
      "weighted avg       0.85      0.85      0.84      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_tfidf))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.42800\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.40811\n",
      "[2]\tvalidation_0-error:0.40744\n",
      "[3]\tvalidation_0-error:0.40111\n",
      "[4]\tvalidation_0-error:0.40089\n",
      "[5]\tvalidation_0-error:0.39578\n",
      "[6]\tvalidation_0-error:0.39200\n",
      "[7]\tvalidation_0-error:0.38922\n",
      "[8]\tvalidation_0-error:0.38689\n",
      "[9]\tvalidation_0-error:0.38433\n",
      "[10]\tvalidation_0-error:0.37811\n",
      "[11]\tvalidation_0-error:0.37644\n",
      "[12]\tvalidation_0-error:0.37311\n",
      "[13]\tvalidation_0-error:0.37156\n",
      "[14]\tvalidation_0-error:0.37000\n",
      "[15]\tvalidation_0-error:0.36767\n",
      "[16]\tvalidation_0-error:0.36656\n",
      "[17]\tvalidation_0-error:0.36367\n",
      "[18]\tvalidation_0-error:0.36044\n",
      "[19]\tvalidation_0-error:0.35556\n",
      "[20]\tvalidation_0-error:0.35144\n",
      "[21]\tvalidation_0-error:0.35000\n",
      "[22]\tvalidation_0-error:0.35011\n",
      "[23]\tvalidation_0-error:0.34778\n",
      "[24]\tvalidation_0-error:0.34633\n",
      "[25]\tvalidation_0-error:0.34467\n",
      "[26]\tvalidation_0-error:0.34311\n",
      "[27]\tvalidation_0-error:0.34156\n",
      "[28]\tvalidation_0-error:0.33844\n",
      "[29]\tvalidation_0-error:0.33678\n",
      "[30]\tvalidation_0-error:0.33611\n",
      "[31]\tvalidation_0-error:0.33489\n",
      "[32]\tvalidation_0-error:0.33533\n",
      "[33]\tvalidation_0-error:0.33478\n",
      "[34]\tvalidation_0-error:0.33322\n",
      "[35]\tvalidation_0-error:0.33133\n",
      "[36]\tvalidation_0-error:0.32867\n",
      "[37]\tvalidation_0-error:0.32889\n",
      "[38]\tvalidation_0-error:0.32656\n",
      "[39]\tvalidation_0-error:0.32711\n",
      "[40]\tvalidation_0-error:0.32556\n",
      "[41]\tvalidation_0-error:0.32433\n",
      "[42]\tvalidation_0-error:0.32289\n",
      "[43]\tvalidation_0-error:0.32122\n",
      "[44]\tvalidation_0-error:0.31889\n",
      "[45]\tvalidation_0-error:0.31922\n",
      "[46]\tvalidation_0-error:0.31622\n",
      "[47]\tvalidation_0-error:0.31533\n",
      "[48]\tvalidation_0-error:0.31511\n",
      "[49]\tvalidation_0-error:0.31433\n",
      "[50]\tvalidation_0-error:0.31389\n",
      "[51]\tvalidation_0-error:0.31389\n",
      "[52]\tvalidation_0-error:0.31322\n",
      "[53]\tvalidation_0-error:0.31322\n",
      "[54]\tvalidation_0-error:0.31389\n",
      "[55]\tvalidation_0-error:0.31344\n",
      "[56]\tvalidation_0-error:0.31222\n",
      "[57]\tvalidation_0-error:0.31122\n",
      "[58]\tvalidation_0-error:0.31067\n",
      "[59]\tvalidation_0-error:0.31000\n",
      "[60]\tvalidation_0-error:0.30756\n",
      "[61]\tvalidation_0-error:0.30722\n",
      "[62]\tvalidation_0-error:0.30711\n",
      "[63]\tvalidation_0-error:0.30678\n",
      "[64]\tvalidation_0-error:0.30533\n",
      "[65]\tvalidation_0-error:0.30511\n",
      "[66]\tvalidation_0-error:0.30422\n",
      "[67]\tvalidation_0-error:0.30333\n",
      "[68]\tvalidation_0-error:0.30278\n",
      "[69]\tvalidation_0-error:0.30100\n",
      "[70]\tvalidation_0-error:0.30056\n",
      "[71]\tvalidation_0-error:0.29978\n",
      "[72]\tvalidation_0-error:0.29756\n",
      "[73]\tvalidation_0-error:0.29744\n",
      "[74]\tvalidation_0-error:0.29711\n",
      "[75]\tvalidation_0-error:0.29656\n",
      "[76]\tvalidation_0-error:0.29611\n",
      "[77]\tvalidation_0-error:0.29556\n",
      "[78]\tvalidation_0-error:0.29544\n",
      "[79]\tvalidation_0-error:0.29533\n",
      "[80]\tvalidation_0-error:0.29389\n",
      "[81]\tvalidation_0-error:0.29333\n",
      "[82]\tvalidation_0-error:0.29278\n",
      "[83]\tvalidation_0-error:0.29156\n",
      "[84]\tvalidation_0-error:0.28989\n",
      "[85]\tvalidation_0-error:0.29033\n",
      "[86]\tvalidation_0-error:0.28967\n",
      "[87]\tvalidation_0-error:0.28911\n",
      "[88]\tvalidation_0-error:0.28789\n",
      "[89]\tvalidation_0-error:0.28756\n",
      "[90]\tvalidation_0-error:0.28756\n",
      "[91]\tvalidation_0-error:0.28600\n",
      "[92]\tvalidation_0-error:0.28567\n",
      "[93]\tvalidation_0-error:0.28511\n",
      "[94]\tvalidation_0-error:0.28356\n",
      "[95]\tvalidation_0-error:0.28289\n",
      "[96]\tvalidation_0-error:0.28422\n",
      "[97]\tvalidation_0-error:0.28256\n",
      "[98]\tvalidation_0-error:0.28189\n",
      "[99]\tvalidation_0-error:0.28167\n",
      "[100]\tvalidation_0-error:0.28244\n",
      "[101]\tvalidation_0-error:0.28156\n",
      "[102]\tvalidation_0-error:0.28144\n",
      "[103]\tvalidation_0-error:0.27900\n",
      "[104]\tvalidation_0-error:0.27944\n",
      "[105]\tvalidation_0-error:0.27933\n",
      "[106]\tvalidation_0-error:0.27911\n",
      "[107]\tvalidation_0-error:0.27833\n",
      "[108]\tvalidation_0-error:0.27922\n",
      "[109]\tvalidation_0-error:0.27833\n",
      "[110]\tvalidation_0-error:0.27767\n",
      "[111]\tvalidation_0-error:0.27678\n",
      "[112]\tvalidation_0-error:0.27600\n",
      "[113]\tvalidation_0-error:0.27644\n",
      "[114]\tvalidation_0-error:0.27611\n",
      "[115]\tvalidation_0-error:0.27522\n",
      "[116]\tvalidation_0-error:0.27500\n",
      "[117]\tvalidation_0-error:0.27500\n",
      "[118]\tvalidation_0-error:0.27500\n",
      "[119]\tvalidation_0-error:0.27467\n",
      "[120]\tvalidation_0-error:0.27400\n",
      "[121]\tvalidation_0-error:0.27556\n",
      "[122]\tvalidation_0-error:0.27511\n",
      "[123]\tvalidation_0-error:0.27456\n",
      "[124]\tvalidation_0-error:0.27356\n",
      "[125]\tvalidation_0-error:0.27222\n",
      "[126]\tvalidation_0-error:0.27156\n",
      "[127]\tvalidation_0-error:0.27111\n",
      "[128]\tvalidation_0-error:0.27144\n",
      "[129]\tvalidation_0-error:0.27044\n",
      "[130]\tvalidation_0-error:0.27067\n",
      "[131]\tvalidation_0-error:0.27067\n",
      "[132]\tvalidation_0-error:0.26944\n",
      "[133]\tvalidation_0-error:0.26856\n",
      "[134]\tvalidation_0-error:0.26789\n",
      "[135]\tvalidation_0-error:0.26733\n",
      "[136]\tvalidation_0-error:0.26578\n",
      "[137]\tvalidation_0-error:0.26589\n",
      "[138]\tvalidation_0-error:0.26533\n",
      "[139]\tvalidation_0-error:0.26378\n",
      "[140]\tvalidation_0-error:0.26578\n",
      "[141]\tvalidation_0-error:0.26456\n",
      "[142]\tvalidation_0-error:0.26356\n",
      "[143]\tvalidation_0-error:0.26333\n",
      "[144]\tvalidation_0-error:0.26500\n",
      "[145]\tvalidation_0-error:0.26489\n",
      "[146]\tvalidation_0-error:0.26467\n",
      "[147]\tvalidation_0-error:0.26467\n",
      "[148]\tvalidation_0-error:0.26411\n",
      "[149]\tvalidation_0-error:0.26244\n",
      "[150]\tvalidation_0-error:0.26411\n",
      "[151]\tvalidation_0-error:0.26289\n",
      "[152]\tvalidation_0-error:0.26389\n",
      "[153]\tvalidation_0-error:0.26167\n",
      "[154]\tvalidation_0-error:0.26167\n",
      "[155]\tvalidation_0-error:0.26033\n",
      "[156]\tvalidation_0-error:0.26089\n",
      "[157]\tvalidation_0-error:0.26111\n",
      "[158]\tvalidation_0-error:0.26044\n",
      "[159]\tvalidation_0-error:0.25956\n",
      "[160]\tvalidation_0-error:0.25944\n",
      "[161]\tvalidation_0-error:0.25789\n",
      "[162]\tvalidation_0-error:0.25856\n",
      "[163]\tvalidation_0-error:0.25744\n",
      "[164]\tvalidation_0-error:0.25689\n",
      "[165]\tvalidation_0-error:0.25744\n",
      "[166]\tvalidation_0-error:0.25678\n",
      "[167]\tvalidation_0-error:0.25556\n",
      "[168]\tvalidation_0-error:0.25589\n",
      "[169]\tvalidation_0-error:0.25622\n",
      "[170]\tvalidation_0-error:0.25600\n",
      "[171]\tvalidation_0-error:0.25544\n",
      "[172]\tvalidation_0-error:0.25478\n",
      "[173]\tvalidation_0-error:0.25544\n",
      "[174]\tvalidation_0-error:0.25522\n",
      "[175]\tvalidation_0-error:0.25511\n",
      "[176]\tvalidation_0-error:0.25467\n",
      "[177]\tvalidation_0-error:0.25444\n",
      "[178]\tvalidation_0-error:0.25433\n",
      "[179]\tvalidation_0-error:0.25522\n",
      "[180]\tvalidation_0-error:0.25456\n",
      "[181]\tvalidation_0-error:0.25389\n",
      "[182]\tvalidation_0-error:0.25344\n",
      "[183]\tvalidation_0-error:0.25322\n",
      "[184]\tvalidation_0-error:0.25333\n",
      "[185]\tvalidation_0-error:0.25289\n",
      "[186]\tvalidation_0-error:0.25256\n",
      "[187]\tvalidation_0-error:0.25211\n",
      "[188]\tvalidation_0-error:0.25211\n",
      "[189]\tvalidation_0-error:0.25167\n",
      "[190]\tvalidation_0-error:0.25111\n",
      "[191]\tvalidation_0-error:0.25111\n",
      "[192]\tvalidation_0-error:0.25000\n",
      "[193]\tvalidation_0-error:0.25089\n",
      "[194]\tvalidation_0-error:0.24978\n",
      "[195]\tvalidation_0-error:0.24933\n",
      "[196]\tvalidation_0-error:0.24911\n",
      "[197]\tvalidation_0-error:0.24878\n",
      "[198]\tvalidation_0-error:0.24822\n",
      "[199]\tvalidation_0-error:0.24856\n",
      "[200]\tvalidation_0-error:0.24856\n",
      "[201]\tvalidation_0-error:0.24900\n",
      "[202]\tvalidation_0-error:0.24911\n",
      "[203]\tvalidation_0-error:0.24867\n",
      "[204]\tvalidation_0-error:0.24867\n",
      "[205]\tvalidation_0-error:0.24833\n",
      "[206]\tvalidation_0-error:0.24844\n",
      "[207]\tvalidation_0-error:0.24822\n",
      "[208]\tvalidation_0-error:0.24833\n",
      "Stopping. Best iteration:\n",
      "[198]\tvalidation_0-error:0.24822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = xgb_model =  XGBClassifier(n_estimators = 1000,  learning_rate = 0.25, max_depth= None, subsample =0.6)\n",
    "xgb_model.fit(X_train_count, y_train,\n",
    "             early_stopping_rounds=10,\n",
    "             eval_set=[(X_test_count, y_test)],\n",
    "             verbose=True)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6766\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = y_pred - y_test\n",
    "aa[aa==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2230 1762]\n",
      " [ 472 4536]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67      3992\n",
      "           1       0.72      0.91      0.80      5008\n",
      "\n",
      "    accuracy                           0.75      9000\n",
      "   macro avg       0.77      0.73      0.73      9000\n",
      "weighted avg       0.77      0.75      0.74      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\"n_estimators\": [50, 100, 300],\n",
    "             \"subsample\":[0.5,0.8,1],\n",
    "             \"max_depth\":[3,5,7],\n",
    "             \"learning_rate\":[0.1,0.01,0.3]}\n",
    "\n",
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 3, \n",
    "                            n_jobs = -1, verbose = 2).fit(X_train_count, y_train,\n",
    "             early_stopping_rounds=10,\n",
    "             eval_set=[(X_test_count, y_test)],\n",
    "             verbose=True)\n",
    "\n",
    "xgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGÄ°STÄ°C REGRESSÄ°ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkdty\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3168  824]\n",
      " [ 559 4449]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      3992\n",
      "           1       0.84      0.89      0.87      5008\n",
      "\n",
      "    accuracy                           0.85      9000\n",
      "   macro avg       0.85      0.84      0.84      9000\n",
      "weighted avg       0.85      0.85      0.85      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
